#summary How to get rolling using Abot quickly

=QuickStart=


===Installing Abot===
  #: Download the latest from the [http://code.google.com/p/abot/downloads/list Downloads] page
  #: Verify the project that will use Abot targets .NET framework version 4.0 or greater
  #: Extract the Abot.dll file and add a reference from your project
  #: Nuget package coming soon

===Using Abot===
  #: Add the following using statements.. 
  {{{
  using Abot.Crawler;
  using Abot.Core;
  using Abot.Poco;
  }}}
  #: Configure Abot using one of the following methods. Look at Abot.Poco.!CrawlConfiguration comments to see what effect each config value has on the crawl [https://code.google.com/p/abot/source/browse/branches/1.1/Abot/Poco/CrawlConfiguration.cs here].
    #: Add the following to the app.config of the assembly using the library
    {{{
<?xml version="1.0"?>
<configuration>
  <configSections>
    <section name="abot" type="Abot.Core.ConfigurationSectionHandler, Abot"/>
  </configSections>

  <abot>
    <crawlBehavior 
      maxConcurrentThreads="10" 
      maxPagesToCrawl="10" 
      maxPagesToCrawlPerDomain="0" 
      maxPageSizeInBytes="0"
      userAgentString="Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; abot v@ABOTASSEMBLYVERSION@ http://code.google.com/p/abot)" 
      crawlTimeoutSeconds="0" 
      downloadableContentTypes="text/html, text/plain" 
      isUriRecrawlingEnabled="false" 
      isExternalPageCrawlingEnabled="false" 
      isExternalPageLinksCrawlingEnabled="false"
      httpServicePointConnectionLimit="200"  
      httpRequestTimeoutInSeconds="15" 
      httpRequestMaxAutoRedirects="7" 
      isHttpRequestAutoRedirectsEnabled="true" 
      isHttpRequestAutomaticDecompressionEnabled="false"
      minAvailableMemoryRequiredInMb="0"
      maxMemoryUsageInMb="0"
      maxMemoryUsageCacheTimeInSeconds="0"      
      maxCrawlDepth="100"
      />
    <politeness 
      isRespectRobotsDotTextEnabled="false"
      robotsDotTextUserAgentString="abot"
      maxRobotsDotTextCrawlDelayInSeconds="5" 
      minCrawlDelayPerDomainMilliSeconds="1000"/>
    <extensionValues>
      <add key="SomeCustomConfigKey1" value="someValue1"/>
      <add key="SomeCustomConfigKey2" value="someValue2"/>
    </extensionValues>
  </abot>
  </configuration>
    }}}
    #: Create an instance of Abot.Poco.!CrawlConfiguration. This approach ignores the app.config values completely. Every app.config value has the same named property on the !CrawlConfiguration object)
    {{{
CrawlConfiguration crawlConfig = new CrawlConfiguration();
crawlConfig.CrawlTimeoutSeconds = 100;
crawlConfig.MaxConcurrentThreads = 10;
crawlConfig.MaxPagesToCrawl = 1000;
crawlConfig.UserAgentString = "abot v1.0 http://code.google.com/p/abot";
crawlConfig.ConfigurationExtensions.Add("SomeCustomConfigValue1", "1111");
crawlConfig.ConfigurationExtensions.Add("SomeCustomConfigValue2", "2222");
etc...
    }}}
    #: Load from app.config then tweek   
    {{{
CrawlConfiguration crawlConfig = AbotConfigurationSectionHandler.LoadFromXml().Convert();
crawlConfig.CrawlTimeoutSeconds = 100;
crawlConfig.MaxConcurrentThreads = 10;
crawlConfig.MaxPagesToCrawl = 1000;
crawlConfig.UserAgentString = "abot v1.0 http://code.google.com/p/abot";
crawlConfig.ConfigurationExtensions.Add("SomeCustomConfigValue1", "1111");
crawlConfig.ConfigurationExtensions.Add("SomeCustomConfigValue2", "2222");
etc...
    }}}
  #: Create an instance of Abot.Crawler.!PoliteWebCrawler
  {{{
//Will use app.config for confguration
PoliteWebCrawler crawler = new PoliteWebCrawler();
  }}}
  {{{
//Will use the manually created crawlConfig object created above
PoliteWebCrawler crawler = new PoliteWebCrawler(crawlConfig, null, null, null, null, null, null, null);
  }}}
  #: Register for events and create processing methods (both synchronous and asynchronous versions available)
  {{{
  crawler.PageCrawlStartingAsync += crawler_ProcessPageCrawlStarting;
  crawler.PageCrawlCompletedAsync += crawler_ProcessPageCrawlCompleted;
  crawler.PageCrawlDisallowedAsync += crawler_PageCrawlDisallowed;
  crawler.PageLinksCrawlDisallowedAsync += crawler_PageLinksCrawlDisallowed;
}}}
{{{
void crawler_ProcessPageCrawlStarting(object sender, PageCrawlStartingArgs e)
{
	PageToCrawl pageToCrawl = e.PageToCrawl;
	Console.WriteLine("About to crawl link {0} which was found on page {1}", pageToCrawl.Uri.AbsoluteUri, pageToCrawl.ParentUri.AbsoluteUri);
}

void crawler_ProcessPageCrawlCompleted(object sender, PageCrawlCompletedArgs e)
{
	CrawledPage crawledPage = e.CrawledPage;

	if (crawledPage.WebException != null || crawledPage.HttpWebResponse.StatusCode != HttpStatusCode.OK)
		Console.WriteLine("Crawl of page failed {0}", crawledPage.Uri.AbsoluteUri);
	else
		Console.WriteLine("Crawl of page succeeded {0}", crawledPage.Uri.AbsoluteUri);

	if (string.IsNullOrEmpty(crawledPage.RawContent))
		Console.WriteLine("Page had no content {0}", crawledPage.Uri.AbsoluteUri);
}

void crawler_PageLinksCrawlDisallowed(object sender, PageLinksCrawlDisallowedArgs e)
{
	CrawledPage crawledPage = e.CrawledPage;
	Console.WriteLine("Did not crawl the links on page {0} due to {1}", crawledPage.Uri.AbsoluteUri, e.DisallowedReason);
}

void crawler_PageCrawlDisallowed(object sender, PageCrawlDisallowedArgs e)
{
	PageToCrawl pageToCrawl = e.PageToCrawl;
	Console.WriteLine("Did not crawl page {0} due to {1}", pageToCrawl.Uri.AbsoluteUri, e.DisallowedReason);
}
}}}
  #: Run the crawl
{{{
CrawlResult result = crawler.Crawl(new Uri("http://localhost:1111/"));

if (result.ErrorOccurred)
	Console.WriteLine("Crawl of {0} completed with error: {1}", result.RootUri.AbsoluteUri, result.ErrorMessage);
else
	Console.WriteLine("Crawl of {0} completed without error.", result.RootUri.AbsoluteUri);

}}}
  #: You Can Pass In A Custom Object
{{{
...
crawler.CrawlBag.MyFoo = new Foo();
...
}}}
Now the Foo instance is accessible anywhere from the crawl context
{{{
void crawler_ProcessPageCrawlStarting(object sender, PageCrawlStartingArgs e)
{
	CrawlContext context = e.CrawlContext;
        context.CrawlBag.MyFoo.Bar();
}
}}}



== Logging ==

Abot uses !Log4Net to log messages. See the app.config files in projects projects Abot.Demo or Abot.Tests.Integration to see how !Log4Net is configured. These log statements are a great way to see whats going on during a crawl. Below is from Abot.Demo project, app.config file. If this prints out to much data for you change the level from "DEBUG" to "INFO".

{{{
  <configSections>
    <section name="log4net" type="log4net.Config.Log4NetConfigurationSectionHandler, log4net" />
  </configSections>

  <log4net>
    <appender name="ConsoleAppender" type="log4net.Appender.ConsoleAppender">
      <layout type="log4net.Layout.PatternLayout">
        <conversionPattern value="[%date] [%thread] [%-5level] - %message%newline" />
      </layout>
    </appender>
    <appender name="RollingFileAppender" type="log4net.Appender.RollingFileAppender">
      <file value="log.txt" />
      <appendToFile value="true" />
      <rollingStyle value="Size" />
      <maxSizeRollBackups value="10" />
      <maximumFileSize value="10240KB" />
      <staticLogFileName value="true" />
      <layout type="log4net.Layout.PatternLayout">
        <conversionPattern value="[%date] [%-3thread] [%-5level] - %message%newline" />
      </layout>
    </appender>
    <root>
      <level value="DEBUG" />
      <appender-ref ref="ConsoleAppender" />
      <appender-ref ref="RollingFileAppender" />
    </root>
  </log4net>
}}}